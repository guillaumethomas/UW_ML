{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Lesson 1. kNN on Iris dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\" style=\"width:250px; height:200px;\"></td>\n",
    "    <td><img src=\"https://www.math.umd.edu/~petersd/666/html/iris_with_labels.jpg\" width=\"250px\"></td>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\" width=\"250px\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "  \n",
    "  <p>This exercise relates to the <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">iris data set</a>,\n",
    "which contains the morphologic variation of Iris flowers of three related species (Iris setosa, Iris virginica and Iris versicolor).</p>\n",
    "<p>Four features were measured from each observation (see image above):</p>\n",
    "<ul>\n",
    "<li>Sepal.Length - sepal length in centimeters</li>\n",
    "<li>Sepal.Width - sepal width in centimeters</li>\n",
    "<li>Petal.Length - petal length in centimeters</li>\n",
    "<li>Petal.Width - petal width in centimeters</li>\n",
    "<li>Species - species of the flower (our outcome variable)</li>\n",
    "</ul>\n",
    "<p>scikit-learn comes with a few small standard datasets that do not require to download any file from some external website.</p>\n",
    "<p>You can check the documentation <a href=\"http://scikit-learn.org/stable/datasets/index.html\">here</a></p>\n",
    "<p>This dataset is built in under variable 'iris'. Let's see how it looks:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a3e222306459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "species_names = list(iris.target_names)\n",
    "print(species_names)\n",
    "# print the integers representing the species of each observation\n",
    "print (iris.target)\n",
    "\n",
    "data = pd.DataFrame(iris.data)\n",
    "data.columns = iris.feature_names\n",
    "data['label'] = iris.target\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.1. How many observations are present for each species?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the command (or commands) here that would give an answer to the above question.\n",
    "#TODO\n",
    "from collections import Counter\n",
    "obs = dict(Counter(iris.target))\n",
    "# data.loc[data['label']==i,'petal length (cm)']\n",
    "\n",
    "print('there is {} samples by specie'.format(list(set(obs.values()))[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.2. Plot the Sepal.Width vs. Sepal.Length, Petal.Width vs. Petal.Length, while color-coding the species.</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the two plot commands here\n",
    "#TODO\n",
    "# create a scatter plot of PETAL LENGTH versus PETAL WIDTH and color by SPECIES\n",
    "# create a custom colormap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "labels = list(iris.target_names)\n",
    "\n",
    "plt.title('petal length vs petal width')\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)')\n",
    "#plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# plt.plot(kind='scatter', x=data['petal length (cm)'], y=data['petal width (cm)'])\n",
    "\n",
    "nb_species = len(obs)\n",
    "# Add label and color\n",
    "for i in range(nb_species):\n",
    "    x_data = data.loc[data['label']==i,'petal length (cm)'].tolist()\n",
    "    y_data = data.loc[data['label']==i,'petal width (cm)'].tolist()\n",
    "    plt.scatter(x_data, y_data,label=labels[i],cmap=cmap_bold)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# create a scatter plot of SEPAL LENGTH versus SEPAL WIDTH and color by SPECIES\n",
    "\n",
    "plt.title('sepal length vs sepal width')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "#plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "# plt.plot(kind='scatter', x=data['sepal length (cm)'], y=data['sepal width (cm)'])\n",
    "\n",
    "for i in range(nb_species):\n",
    "    x_data = data.loc[data['label']==i,'sepal length (cm)'].tolist()\n",
    "    y_data = data.loc[data['label']==i,'sepal width (cm)'].tolist()\n",
    "    plt.scatter(x_data, y_data,label=labels[i])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.3. Which of the plots allows for easier determination of the flower type?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the plot that clearly separates the classes\n",
    "print('PETAL LENGTH versus PETAL WIDTH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>After the initial exploratory data analysis.</p>\n",
    "\n",
    "<h3>Q.4. Write the command to split the data into 70% train and 30% test, to prepare for k-NN modelling:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# first split the dataset into its attributes and labels\n",
    "X = data.iloc[:, :-1].values  \n",
    "y = data.iloc[:, 4].values  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.5. Write the Python command that performs k-NN fit using Petal.Width and Petal.Length only using 2 neighbors.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as Kneig\n",
    "\n",
    "# Instantiate learning model (k = 3)\n",
    "clf = Kneig(n_neighbors=3)\n",
    "\n",
    "# Fitting the model\n",
    "fitting = clf.fit(X_train, y_train)\n",
    "print(fitting.score(X_test, y_test))\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "delta = sum(map(lambda x,y: bool(x-y),y_pred,y_test))\n",
    "print('the prediction model has made {} errors'.format(delta) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.6. Evaluate your algorithm using the confusion_matrix and classification_report methods of the sklearn.metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred,target_names=species_names))\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.7. What accuracy did you obtain?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the obtained accuracy is {}'.format(round(acc,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.8. Try with different values of k (3 and 5), do you observe any difference in your result? Explain.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as Kneig\n",
    "\n",
    "# Instantiate learning model (k = 5)\n",
    "clf = Kneig(n_neighbors=5)\n",
    "\n",
    "# Fitting the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "delta = sum(map(lambda x,y: bool(x-y),y_pred,y_test))\n",
    "print('the prediction model has made {} errors'.format(delta) )\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred,target_names=species_names))\n",
    "print(accuracy_score(y_test, y_pred, normalize=True))\n",
    "\n",
    "print('Between 3 and 5 the accuracy does not change much, the precision depends on how the test set is being sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q.9. List three methods that can be used to improve prediction quality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# 1. Choosing the most applicable set of variables\n",
    "print('Having distinctive clusters of data using Dunn Index and silhouette score')\n",
    "\n",
    "\n",
    "# Silhouette score  'sepal length vs sepal width'\n",
    "b = np.delete(data.values,[2,3,4],1)\n",
    "c = np.delete(data.values,[0,1,2,3],1).flatten() #transforming vector into array\n",
    "silh = metrics.silhouette_score(b,c)\n",
    "print('sepal length vs sepal width silhouette score {}'.format(round(silh,2)))\n",
    "\n",
    "# Silhouette score for 'petal length vs petal width'\n",
    "b = np.delete(data.values,[0,1,4],1)\n",
    "silh = metrics.silhouette_score(b,c)\n",
    "print('petal length vs petal width silhouette score {}'.format(round(silh,2)))\n",
    "\n",
    "print('the score indicates that petal length vs petal width is the best set')\n",
    "\n",
    "# 2. Choosing an optimal value for k for kNN\n",
    "print('\\ngenerally sqrt(n) is a good value for k')\n",
    "for i in range(1,8):\n",
    "    print('\\n{}'.format(i))\n",
    "    clf = Kneig(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred, normalize=True))\n",
    "    print('Perform Cross-validation')\n",
    "    scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "    # print(scores)\n",
    "    print('Accuracy {} (+/- {})'.format(round(scores.mean(),2), round(scores.std() * 2),3))\n",
    "    \n",
    "\n",
    "# 3. Not overfitting the data in general\n",
    "scores = cross_val_score(clf, iris.data, iris.target, scoring=\"neg_mean_squared_error\",cv=10)\n",
    "print('\\nMinmize MSE') \n",
    "print(-scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
